%File: formatting-instruction.tex

\documentclass[letterpaper]{article}
\usepackage{aaai}
\usepackage{times}
\usepackage{helvet}
\usepackage{courier}
\usepackage{latexsym}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{epsfig}
\usepackage{epsf}



\newtheorem{THEOREM}{Theorem}
\newenvironment{theorem}{\begin{THEOREM} }%
                        {\end{THEOREM}}
\newtheorem{LEMMA}[THEOREM]{Lemma}
\newenvironment{lemma}{\begin{LEMMA} }%
                      {\end{LEMMA}}
\newtheorem{PROPOSITION}[THEOREM]{Proposition}
\newenvironment{prop}{\begin{PROPOSITION} }
                      {\end{PROPOSITION}}
\newtheorem{COROLLARY}[THEOREM]{Corollary}
\newenvironment{corollary}{\begin{COROLLARY}  }%
                          {\end{COROLLARY}}
\newtheorem{EXAMPLE}{Example}
\newenvironment{example}{\begin{EXAMPLE} \rm}%
                            {\end{EXAMPLE}}

\newtheorem{DEFINITION}{Definition}
\newenvironment{definition}{\begin{DEFINITION} \rm }
                            {\end{DEFINITION}}

\newenvironment{proof}{{\bf Proof:}}{\hfill\rule{2mm}{2mm} \vspace*{0.2cm}}
\newenvironment{proof1}{{\bf Proof:}} {\vspace*{0.2cm}}
\newcommand{\qed}{\hfill\rule{2mm}{2mm}}

\newcommand{\xvec}[1]{\smash{\vec{#1}}}
\newcommand{\newd}[1]{\mbox{\underline{\it\smash{#1}\vphantom{\lower.1ex\hbox{x}}}}}

\newcommand\ie{{\it i.e.}}
\newcommand\etc{{\it et al. }}
\newcommand\eg{{\it e.g.}}

\newcommand{\psig}{\Sigma_p}

\newcommand{\emodels}{\models_\Eaxiom}
\newcommand{\slmodels}{\models}
\newcommand{\slentails}{\models}
\def \notmodels {\,{\mathrel|\joinrel\neq}\,}
\newcommand{\operator}[2]{\mbox{\boldmath $#1$\hspace*{-#2ex}}}
\newcommand{\B}{\operator{B}{.2}}

\newcommand\red[1]{\M{(#1)\!\downarrow}}
\newcommand\UP[1]{\M{\mbox{\ssf UP}(#1)}}
\newcommand\VP[1]{\M{\mbox{\ssf VP}(#1)}}

\newcommand\obar[1]{\M{\overline{#1}}}
\newcommand\order[1]{\M{\parallel\!#1\!\parallel}}
\newcommand\up{\M{\mbox{\ssf UP}}}
\newcommand\vp{\M{\mbox{\ssf VP}}}


\newcommand{\properplus}{\mbox{proper$^+$}}
\newcommand\forget{\mbox{forget}}
\newcommand{\limp}{\M{\supset}}
\newcommand{\Eaxiom}{{\M{\cal E}}}

\newcommand{\SL}{\M{{\cal S}\!{\cal L}}}
\newcommand{\Knows}{\mbox{\bf Knows}}

\gdef\M#1{\ifmmode #1\else$#1$\fi}
\newcommand\ssf{\small\sf}

\newcommand{\Sa}{S_{\alpha}}
\newcommand{\Lan}{\M{{\cal L}}}

\newcommand{\gnd}{\mbox{gnd}}
\newcommand\entails\models

\newcommand{\at}{\M{{\cal D}}}
\newcommand{\init}{\M{{\cal D}_{S_0}}}
\newcommand{\calC}{\M{{\cal C}}}
\newcommand{\FC}{\M{{\cal F}_\at}}
\newcommand{\CM}{\M{{\cal C}_\at}}
\newcommand{\TR}{\M{{\cal T}}}
\newcommand{\EX}{\M{{\cal E}_\at}}
\newcommand{\clo}{\M{bcl}}
\newcommand{\prog}{\M{prog}}

\newcommand{\trans}{\rightarrow_\at}

\newcommand{\Eequiv}{\Leftrightarrow_{\Eaxiom}}

%\frenchspacing
\pdfinfo{
/Title (Formatting Instructions for Authors Using LaTeX)
/Subject (AAAI Publications)
/Author (AAAI Press)}
\setcounter{secnumdepth}{0}
 \begin{document}
% The file aaai.sty is the style file for AAAI Press
% proceedings, working notes, and technical reports.
%
\title{A First-Order Interpreter for Knowledge-based Golog with Sensing\\ based on Exact Progression and Limited Reasoning}
\author{Cognitive robotics, Reasoning about actions, 
}
\maketitle
\begin{abstract}
\begin{quote}
While founded on the situation calculus, current implementations of Golog are based on the closed-world assumption (CWA), dynamic versions of CWA, or the domain closure assumption. Also, they are exclusively based on regression. In this paper, we propose a first-order interpreter for knowledge-based Golog with sensing based on exact progression and limited reasoning. We assume infinitely many unique names and handle first-order disjunctive information in the form of the so-called \properplus\ KBs. Our implementation is based on the progression and limited reasoning algorithms for \properplus\ KBs proposed by Liu, Lakemeyer and Levesque. To improve efficiency, we implement the two algorithms by grounding via a trick.
The interpreter is offline but the programmer can use two operators to specify offline execution for parts of programs. The search operator returns a conditional plan as execution of the operand program. The planning operator is used when locally complete information is available and calls a state-of-the-art planner to generate a plan.

\end{quote}
\end{abstract}

\section{Introduction}

?? where to mention LBGolog

When it comes to high-level robotic control, the idea of high-level program execution as embodied by the
Golog language \cite{Golog} provides a useful alternative to planning. Golog is theoretically based on the situation calculus \cite{Rei01}, which is a first-order language. However, current implementations of Golog offer limited first-order capabilities. For example, implementation of classic Golog is based on the closed-world assumption (CWA). Although variants of Golog have been proposed to handle incomplete information and sensing, their implementations resort to dynamic versions of CWA or at least the domain closure assumption (DCA). For example, implementation of IndiGolog \cite{GLS01} is based on a just-in-time assumption, which reduces to a dynamic CWA. The interpreter for knowledge-based Golog as proposed by Reiter \shortcite{Rei01a} is based on DCA and reduces first-order reasoning to propositional one. However, in many real-world applications, it is inappropriate to have CWA, or dynamic CWA, or domain closure axiom.

An essential component of any Golog interpreter is a query evaluation module, which solves the projection problem, that is, decide if a formula holds after a sequence of actions have been performed. Two powerful methods to solve the projection problem are {\em
regression} and {\em progression}. Roughly, regression reduces a
query about the future to a query about the initial knowledge base
(KB). Progression, on the other hand, changes the initial KB
according to the effects of each action and then checks whether the
formula holds in the resulting KB.
One advantage of progression
compared to regression is that after a KB has been progressed, many
queries about the resulting state can be processed without any extra
overhead. Moreover, when the action sequence becomes very long, as
in the case of a robot operating for an extended period of time,
regression simply becomes unmanageable. However, current implementations
of Golog are exclusively based on regression. This might be due to the negative result that
in general progression is not first-order definable. However, recently,
Liu and Lakemeyer \shortcite{LL09} showed that for the so-called local-effect actions, progression is always first-order definable and computable.

Golog interpreters can be put into three categories: online, offline, and a combination of the two.
An online interpreter is incomplete because no backtracking is allowed, while an offline interpreter is computationally expensive because of the much larger search space. In the presence of sensing, Reiter's interpreter for knowledge-based Golog is online, while the one for sGolog \cite{Lak99} is offline, generating a conditional plan. IndiGolog combines online execution with offline execution of parts of programs, specified by the programmer with a search operator. However, unlike sGolog, IndiGolog ignores sensing results during offline execution of programs.
To improve efficiency of Golog interpreters, there has been work on exploiting state-of-the-art planners. For example, Baier \etc\ \shortcite{BFM07} developed an approach for compiling procedural domain control knowledge written in a Golog-like program into a planning instance which can then be solved by a planner.
Cla{\ss}en \etc\ \shortcite{Cla07} proposed the idea of calling a planner to achieve a goal during the execution of a Golog program.

Our work in this paper is based on existing work on the so-called proper$^+$ KBs for representing first-order disjunctive information. 
Intuitively, a \properplus\ KB is equivalent to a possibly infinite set of ground clauses. Our solution to the projection problem is based on exact progression and limited reasoning, and we exploit existing results regarding proper$^+$ KBs. We call our version of Golog LBGolog (Limited-Belief-based Golog).
Since the deduction problem for \properplus\ KBs is undecidable, Liu, Lakemeyer and Levesque \shortcite{LLL04} proposed a logic of limited belief called the subjective logic $\SL$, and proved that $\SL$-based reasoning with \properplus\ KBs is decidable. Reasoning based on $\SL$ is logically sound and sometimes complete. Given disjunctive information, it performs unit propagation, but only does case analysis in a limited way.
On the other hand, Liu and Lakemeyer \shortcite{LL09} showed that for a restricted class of local-effect actions and \properplus\ KBs, progression is not only first-order definable but also efficiently computable.

In this paper, we propose an interpreter for knowledge-based Golog with first-order incomplete information and sensing. We do not assume any of the CWA, dynamic CWA and DCA. The incomplete information is in the form of the so-called \properplus\ KBs \cite{LL02}; 
To improve efficiency, we implement the reasoning (right now, we do not do any case analysis) and progression procedures by grounding. The trick here is to use an appropriate number of special constants, which actually carries first-order information.
We provide a search operator, which, unlike in indiGolog, returns a conditional program where branchings are conditioned on the results of sensing actions. We also provide a planning operator, which is used with a program when locally complete information is available, and calls a state-of-the-art planner to generate a sequence of actions constituting a legal execution of the program.
We have experimented our interpreter with Wumpus world, blocks world, Unix domain, and service robot domains; the results showed the feasibility and efficiency of our approach.

%The rest of the paper is organized as follows. In the next section, we introduce the background work of this paper. Then we present the syntax and semantics of LBGolog. Next, we show how to implement progression and query evaluation by grounding. In the following section,
%we describe our implementation of a LBGolog interpreter and prove its correctness. After presenting some experimental results and examples, we discuss related work and conclude.

\section{Background work}
In this section, we introduce the background work of this paper, \ie, proper$^+$ KBs, situation calculus, progression, subjective logic, and closed-world assumption on knowledge.

We start with a first-order language $\Lan$
with equality, a countably infinite set of constants, which are
intended to be unique names, and no other function symbols. A literal is an atom or its negation, and a clause is a set of literals, identified with their disjunction.
We let $\Eaxiom$ denote the union of the axioms of equality and the infinite
set $\{(d\neq d')\mid d$ and $d'$ are distinct constants$\}$.
Let $\phi$
be a formula, and let $\mu$ and $\mu'$ be two expressions. We denote
by $\phi(\mu/\mu')$ the result of replacing every occurrence of
$\mu$ in $\phi$ with $\mu'$. We write $\phi^x_d$ to denote $\phi$ with all free occurrences of variable $x$ replaced by constant $d$.

\subsection{Proper$^+$ KBs}

Proper$^+$ KBs were proposed by Lakemeyer and Levesque
\shortcite{LL02}  for representing first-order disjunctive information.
Intuitively, a $\properplus$ KB is equivalent to a (possibly
infinite) set of ground clauses.
To formally define proper$^+$ KBs, we let
$e$ range over ewffs, \ie, quantifier-free formulas whose only
predicate is equality, and we let $\forall\phi$ denote the universal
closure~of~$\phi$. We use $\theta$ to range over substitutions of all variables by constants, and
write $\phi\theta$ as the result of applying the substitution $\theta$ to
$\phi$.

\begin{definition}\label{def:properplus}
Let $e$ be an ewff and $c$ a clause. Then a formula of the form
$\forall(e\limp c)$ is called a $\forall$-clause.  A KB is called
{\em \properplus} if it is a finite non-empty set of
$\forall$-clauses. Given a $\text{proper}^+$ KB $\Sigma$,
{$\gnd(\Sigma)$} is defined as
$\{c\theta\mid \forall(e\supset c)\in \Sigma$ and $\Eaxiom \models e\theta\}$.
\end{definition}

\subsection{Situation calculus}

The language $\Lan_{sc}$ of the situation calculus \cite{Rei01} is a
many-sorted first-order language suitable for describing dynamic
worlds. There are three disjoint sorts: $action$ for actions,
$situation$ for situations, and $object$ for everything else.
$\Lan_{sc}$ has the following components: a constant $S_0$ denoting
the initial situation; a binary function $do(a,s)$ denoting the
successor situation to $s$ resulting from performing action $a$; a
binary predicate $Poss(a,s)$ meaning that action $a$ is possible in
situation $s$;  action functions, \eg, $move(x,y)$; a finite number
of relational fluents, \ie, predicates taking a situation term as
their last argument, \eg, $ontable(x,s)$; and a finite number of
situation-independent predicates. We ignore functional fluents in this paper.

We relate $\Lan_{sc}$ to $\Lan$ as follows: There
is a set of constants of sort object which are constants of $\Lan$.  The
situation-independent predicates and relational fluents are predicates from
$\Lan$. That is, if $P(\xvec{x})$ is a situation-independent predicate, and
$F(\xvec{x},s)$ is a relational fluent, then $P(\xvec{x})$ and $F(\xvec{x})$
are predicates from $\Lan$.

Often, we need to restrict our attention to formulas that refer to a
particular situation. For this purpose, we say that a formula $\phi$
is uniform in a situation term $\tau$, if $\phi$ does not mention
any other situation terms except $\tau$, does not quantify over
situation variables, and does not mention $Poss$.

A particular domain of application is specified by a basic
action theory (BAT) of the following form:
\[\at = \Sigma \cup \at_{ap} \cup \at_{ss} \cup \at_{una}\cup \at_{S_0}, \mbox{
where} \]
\begin{enumerate}

\item $\Sigma$ is the set of the foundational axioms for situations.

\item $\at_{ap}$ is a set of action precondition axioms, one for each action, of the form
\(Poss(A(\xvec{x}),s)\equiv \Pi_A(\xvec{x},s)\), where $\Pi_A(\xvec{x},s)$ is uniform in $s$.

\item $\at_{ss}$ is a set of
successor state axioms (SSAs), one for each
fluent, of the form
$F(\xvec{x},do(a,s))\equiv \gamma_F^+(\xvec{x},a,s)\vee (F(\xvec{x})\wedge
\neg \gamma_F^-(\xvec{x},a,s))$,
where $\gamma_F^+(\xvec{x},a,s)$ and  $\gamma_F^-(\xvec{x},a,s)$ are uniform in $s$.

\item ??$\at_{una}$ is the set of unique names axioms for actions:
\( A(\xvec{x})\neq A'(\xvec{y}),\;\mbox{ and }\;
A(\xvec{x})=A(\xvec{y})\supset \xvec{x}=\xvec{y},\) where $A$ and
$A'$ are distinct action functions.

\item $\at_{S_0}$, the initial KB, is a set of sentences uniform in
$S_0$.
\end{enumerate}

Following Levesque \shortcite{Lev96}, we extend the situation calculus to
accommodate sensing actions.
Assume that in addition to ordinary actions (called physical actions) that change the world, we also
have binary sensing actions that do not change the world but tell the agent
whether some condition $\phi$ holds in the current situation.  We use the
predicate $SF(a,s)$ to characterize what the sensing action tells the agent
about the world. Now our BAT has an extra component
$\at_{sf}$, which is a set of sensed fluent axioms (SFAs), one for each
action, of the form
\(SF(A(\xvec{x}),s)\equiv \Psi_A(\xvec{x},s),\)
where $\Psi_A(\xvec{x},s)$ is uniform in $s$.
To simplify presentation, for each ground sensing action $\alpha$, we introduce two
auxiliary actions $\alpha_T$ and $\alpha_F$, which represent $\alpha$ with sensing results
$true$ and $false$, respectively.

\subsection{Progression}

Lin and Reiter \shortcite{LR97} formalized the notion of
progression.
Let $\at$ be a basic action theory, and $\alpha$ a
ground action. We denote by $S_\alpha$ the situation term
$do(\alpha, S_0)$.

\begin{definition}
Let $M$ and $M'$ be structures with the same domains for sorts {\em
action} and {\em object}. We write $M\sim_{S_\alpha} M'$ if the
following two conditions hold: (1) $M$ and $M'$ interpret all
situation-independent predicate and function symbols identically.
(2) $M$ and $M'$ agree on all fluents at $S_\alpha$: For every
relational fluent $F$, and every variable assignment $\sigma$, $M,
\sigma \models F(\vec{x}, S_\alpha)$ iff $M', \sigma \models
F(\vec{x}, S_\alpha)$.
\end{definition}

We denote by $\Lan_{sc}^2$ the second-order extension of
$\Lan_{sc}$. The notion of uniform formulas carries over to
$\Lan_{sc}^2$.

\begin{definition} Let $\at_{S_\alpha}$ be a set of sentences in
$\Lan^2_{sc}$ uniform in $S_\alpha$. $\at_{S_\alpha}$ is a
progression of the initial KB $\at_{S_0}$ wrt $\alpha$ if for any
structure $M$, $M$ is a model of $\at_{S_\alpha}$ iff there is a
model $M'$ of $\at$ such that $M\sim_{S_\alpha} M'$.
\end{definition}

Lin and Reiter showed that progression is not first-order definable in general.
Recently, Liu and Lakemeyer \shortcite{LL09} showed that for local-effect actions, progression is always first-order definable and computable. Their proof is a very simple one via
the concept of forgetting. For a restricted class of local-effect actions and \properplus\ KBs, they showed that progression is not only first-order definable but also
efficiently computable.

Actions in many dynamic domains have only local effects in the sense
that if an action $A(\xvec{c}\,)$ changes the truth value of an atom
$F(\xvec{d},s)$, then $\xvec{d}$ is contained in $\xvec{c}\,$.

\begin{definition} \label{def-local-effect}
An SSA is local-effect if both $\gamma_F^+(\xvec{x},a,s)$ and
$\gamma_F^-(\xvec{x},a,s)$ are disjunctions of formulas of the form
$\exists\xvec{z}\,[a=A(\xvec{u})\wedge \phi(\xvec{u},s)]$, where $A$
is an action function, $\xvec{u}$ contains $\xvec{x}$, $\xvec{z}$ is
the remaining variables of $\xvec{u}$. An action theory is local-effect if each SSA is
local-effect.
\end{definition}

\begin{theorem}\label{prog-thm}
Let $\at$ be local-effect,
and $\alpha=A(\vec{c})$ a ground action. We use $\Omega(s)$ to denote the set of $F(\vec{a},s)$ where $F$ is a fluent, and $\vec{a}$ is contained in $\vec{c}$. Then the following is a  progression of $\at_{S_0}$ wrt $\alpha$
\[forget(\at_{S_0} \cup \at_{ss}[\Omega],\Omega(S_0))(S_0/\Sa),\]
 where $\at_{ss}[\Omega]$ is the instantiation of $\at_{ss}$ wrt $\Omega$.
\end{theorem}
It is well known that forgetting an atom from a first-order formula can be done by a simple syntactic operation, and the result is a first-order formula.

\begin{definition}
An SSA is essentially quantifier-free if for each ground action
$\alpha$, by using $\at_{una}$, both
$\gamma_F^+(\xvec{x},\alpha,s)$ and $\gamma_F^-(\xvec{x},\alpha,s)$
can be simplified to quantifier-free formulas.
\end{definition}

Thus, when $\at_{ss}$ is essentially quantifier-free, its instantiation wrt a ground action $\alpha$ and $S_0$ is definable as a proper$^+$ KB.  Liu and Lakemeyer \shortcite{LL09} proved the following:

\begin{theorem} Suppose that $\at$ is local-effect, $\at_{ss}$ is essentially
quantifier-free, and $\at_{S_0}$ is proper$^+$. Then progression of
$\at_{S_0}$ wrt any ground action $\alpha$ is definable as a
proper$^+$ KB and can be efficiently computed.
\end{theorem}

We use $prog(\at_{S_0},\alpha)$ to denote a proper$^+$ KB which is a progression of $\at_{S_0}$ wrt $\alpha$.
It is straightforward to generalize the notation to $prog(\at_{S_0},\sigma)$, where $\sigma$ is a ground situation.

We now extend the notion of progression to accommodate sensing actions.
\begin{definition} Let $\alpha$ be a ground sensing action and $\mu \in \{T,F\}$. Let $\at_{S_\alpha}$ be a set of sentences in
$\Lan^2_{sc}$ uniform in $S_\alpha$. $\at_{S_\alpha}$ is a
progression of the initial KB $\at_{S_0}$ wrt $\alpha_\mu$ if for any
structure $M$, $M$ is a model of $\at_{S_\alpha}$ iff there is a
model $M'$ of $\at\cup \{(\neg) SF(\alpha,S_0)\}$ such that $M\sim_{S_\alpha} M'$, where there is $\neg$ in front of $SF$ iff $\mu=T$.
\end{definition}

It is easy to show the following:
\begin{theorem}
Let $\alpha=A(\vec{c})$ be a ground sensing action. Then
$(\at_{S_0} \cup (\neg) \Psi_A(\vec{c},S_0))(S_0/\Sa)$ is a progression of $\at_{S_0}$ wrt $\alpha_\mu$, where there is $\neg$ in front of $\Psi_A$ iff $\mu=T$.
\end{theorem}

If $\Psi_A$ is quantifier-free, then $(\neg)\Psi_A$ can be converted into a CNF.
Thus we have the following result for \properplus KBs:

\begin{theorem} If $\at_{sf}$ is quantifier-free and $\at_{S_0}$ is proper$^+$, then progression of
$\at_{S_0}$ wrt any ground sensing action is definable as a
proper$^+$ KB and can be efficiently computed.
\end{theorem}

\subsection{The subjective logic $\SL$}

A popular way of specifying a limited reasoning service is through a logic of
belief. With
the goal of specifying a reasoning service for first-order KBs with
disjunctive information in the form of \properplus\ KBs,
Liu, Lakemeyer and Levesque \shortcite{LLL04}
propose a logic of limited belief called the
subjective logic $\SL$. Reasoning based on $\SL$ is logically sound and
sometimes complete.  Given disjunctive information, it performs unit propagation,
but only does case analysis in a limited way.
To save space, later we will refer to \cite{LLL04} by (LLL04).

The
language $\SL$ is a first-order logic with equality whose atomic formulas are
belief atoms of the form $\B_k \phi$ where $\phi$ is a formula of
${\cal L}$ and $\B_k$ is a modal operator for any $k\geq 0$.  $\B_k\phi$ is
read as ``$\phi$ is a belief at level $k$''. We let $\SL_k$ denote the set of $\SL$-formulas whose only modal operators are $B_j$ for $j\leq k$. We call formulas of $\Lan$ objective formulas, and formulas of $\SL$ subjective formulas

To define the semantics of $\SL$,
we introduce some notation.
Let $s$ be a
set of ground clauses. The notation $\UP{s}$ is used to denote the closure of
$s$ under unit propagation, that is, the least set $s'$ satisfying:
1. $s \subseteq s'$; and
2. if a literal $\rho \in s'$ and $\{\obar{\rho}\}\cup c \in s'$, where $\obar{\rho}$
denotes the complement of $\rho$, then $c \in s'$.
Let $\phi\in\Lan$. The notation
$\red{\B_k\phi}$, called belief reduction, is defined as follows:

\begin{enumerate}

\item $\red{\B_k c}\,\,=\,\,\B_k c$, where $c$ is a clause;

\item $\red{\B_k e}\,\,=\,\,e$, where $e$ is an equality literal;

\item $\red{\B_k\lnot\lnot\phi}\,\,=\,\,\B_k\phi$;

\item $\red{\B_k(\phi\lor\psi)}\,\,=\,\,(\B_k\phi\lor\B_k\psi)$,
where $\phi$ or $\psi$ is not a clause; and
 $\red{\B_k\lnot(\phi\lor\psi)}\,\,=\,\,(\B_k\lnot\phi\land\B_k\lnot\psi)$;

\item $\red{\B_k\exists{x}\phi}\,\,=\,\,\exists{x}\B_k\phi$; and $\red{\B_k\lnot\exists{x}\phi}\,\,=\,\,\forall{x}\B_k\lnot\phi$.
\end{enumerate}



Sentences of \SL\ are interpreted via a {\it setup}\index{setup}, which is a
set of non-empty {\em ground clauses}.
Let $s$ be a setup. For any
sentence $\varphi \in \SL$, $s\slmodels \varphi$
(read ``$s$ satisfies $\varphi$'')
is defined inductively as follows:
\begin{enumerate}
\item $s\slmodels (d=d')$ iff $d$ and $d'$ are the same constant;
\item $s\slmodels \neg \varphi$ iff $s \notmodels \varphi$;
\item $s\slmodels \varphi \vee \omega$ iff $s\slmodels \varphi$ or $s\slmodels \omega$;
\item $s\slmodels\exists x \varphi$ iff for some constant $d$, $s \slmodels \varphi^x_d$;
\item $s\slmodels \B_k \phi$ iff one of the following holds:
\begin{enumerate}
\item {\it subsume}: $k=0$, $\phi$ is a clause $c$,
and there is $c'\in\UP{s}$ s.t. $c'\subseteq c\}$;

\item {\it reduce}: $\phi$ is not a clause and $s \slmodels \red{\B_k \phi}$;
\item {\it split}: $k>0$ and there is some $c\in s$ such that for all $\rho\in
  c$,\, $s\cup \{\rho\}\slmodels \B_{k-1}\phi$.
\end{enumerate}
\end{enumerate}
As usual, a set $\Gamma$ of sentences entails a sentence $\varphi$, written
$\Gamma \models \varphi$, if for every setup $s$ such that $s$ satisfies every sentence of $\Gamma$, we have that $s$ satisfies $\varphi$.

The $\SL$-based reasoning problem is to decide if $\B_0 \Sigma\models \B_k \phi$, given a KB $\Sigma$ and a query $\phi$. In (LLL04), the authors showed that $\SL$-based reasoning for proper$^+$ KBs is decidable by presenting
a decision procedure called $W$. Later, Liu and Levesque \cite{LL05} showed that $\SL$-based reasoning with proper$^+$ KBs is not only decidable but also tractable when
both the KB and the query use a bounded number of variables.

\subsection{Closed-world assumption on knowledge}

In his work on knowledge-based programming, Reiter \cite{Rei} introduced the closed-world assumption on knowledge that a given ${\cal K}$ of axioms about what an agent knows captures everything that the agent knows; any knowledge sentences not following logically from ${\cal K}$ are taken to be false.
 This assumption relieves the axiomatizer from having to figure out the relevant lack of knowledge axioms when given what the agent does know. Let $\Sigma$ be a proper$^+$ KB. We adapt Reiter's idea to $\SL$ as follows:

\begin{definition}
\(\clo(B_0\Sigma) \overset{def}{=}
B_0 \Sigma \cup \{\neg B_k\phi \mid B_0\Sigma \not \models B_k\phi\}.\)
\end{definition}

By an important result from (LLL04) that
$\models \B_0 \Sigma\limp\B_k\phi$ \,\,iff\,\, $\gnd(\Sigma)\entails\B_k\phi$, we
have \(\clo(B_0\Sigma) =
B_0 \Sigma \cup \{\neg B_k\phi \mid \gnd(\Sigma) \models \neg B_k\phi\}.\)
Thus it is easy to prove

\begin{theorem} \label{bcl-thm} Let $\Sigma$ be a proper$^+$ KB. Then
\begin{enumerate}
\item $\clo(B_0\Sigma)$ is satisfiable.

\item For any $\varphi \in \SL$, $\clo(B_0\Sigma) \models \varphi$ or $\clo(B_0\Sigma) \models \neg \varphi$.

\item For any $\varphi \in \SL$, $gnd(\Sigma)\models \varphi$ iff $\clo(B_0\Sigma) \models \varphi$.
\end{enumerate}
\end{theorem}

Finally, we relate reasoning about subjective formulas to reasoning about objective formulas. Let $\varphi \in \SL$. We define its objective formula, denoted by $\varphi_o$, as the formula obtained from $\varphi$ by replacing each belief atom $B_k \phi$ with $\phi$. A \properplus\ KB $\Sigma$ is proper if $\gnd(\Sigma)$ is a consistent set of ground literals.
It is easy to show that when a proper KB $\Sigma$ is complete, $\gnd(\Sigma) \models \varphi$ iff $\Eaxiom \cup \Sigma$ classically entails $\varphi_o$. Thus we have

\begin{theorem} \label{comp-thm} Let $\Sigma$ be a complete proper KB. Then
$\clo(B_0\Sigma) \models \varphi$ iff $\Eaxiom \cup \Sigma$ classically entails $\varphi_o$.
\end{theorem}


\section{LBGolog: syntax and semantics}
In this section, we introduce the syntax and semantics of LBGolog, and give examples of programs in LBGolog.

The following are the programming constructs of LBGolog. A difference with normal Golog is that all tests $\phi$ are $\SL$ formulas with only $B_0$ modal operators. For readability, we also write $B_0 \psi$ as $\Knows(\psi)$.

\noindent
\begin{tabular}{llr}
%$nil$ & \hspace*{-1.5cm} empty program \\
1. &\hspace*{-0.3cm}$\alpha$ & \hspace*{-2.3cm} primitive action \\
% $\beta$ & sensing action \\
2. &\hspace*{-0.3cm}$\phi?$  & \hspace*{-2.3cm} test action \\
3. &\hspace*{-0.3cm}$(\delta_1 ; \delta_2)$ & \hspace*{-2.3cm} sequence \\
4. &\hspace*{-0.3cm}$(\delta_1 \thinspace | \thinspace \delta_2)$ & \hspace*{-2.3cm} nondeterministic choice of actions \\
5. &\hspace*{-0.3cm}$(\pi\vec{x}. \phi \wedge \delta)$ & \hspace*{-2.3cm} guarded nondet. choice of arguments \\
6. &\hspace*{-0.3cm}$\delta^*$ & nondeterministic iteration \\
7. &\hspace*{-0.3cm}\textbf{if} $\phi$ \textbf{then} $\delta_1$ \textbf{else} $\delta_2$ {\bf endIf} & conditional \\
8. &\hspace*{-0.3cm}\textbf{while} $\phi$ \textbf{do} $\delta$ {\bf endWhile} & while loop \\
9. &\hspace*{-0.3cm}\textbf{proc} $P(\vec{x})$ $\delta$ {\bf endProc} & procedure definition \\
10. &\hspace*{-0.3cm} $P(\vec{c})$ & procedure call \\
11. & \hspace*{-0.3cm}$\Sigma \delta$ & search operator \\
12. & \hspace*{-0.3cm}$\Upsilon (\tau,\delta)$ & planning operator \\
\end{tabular}

The first 10 constructs, called the basic constructs, are the same as those of Golog except that here we have guarded nondeterministic choice of arguments $\pi\vec{x}. \phi \wedge \delta$, where any variable of $\vec{x}$ must appear in $\phi$, and it is executed by nondeterministically picking $\vec{x}$ such that $\phi(\vec{x})$ holds and then performing $\delta(\vec{x})$. We call a program basic if it uses only basic constructs.
As in IndiGolog, there is a search operator $\Sigma \delta$, where $\delta$ is a basic program, which specifies that lookahead should be performed over program $\delta$ to ensure that nondeterministic choices are resolved in a way that guarantees its successful completion. We allow $\delta$ in $\Sigma \delta$ to use sensing actions. Unlike IndiGolog, the search operator returns a conditional program ready to be executed online, where branchings are conditioned on the results of sensing actions.

In addition, there is a planning operator $\Upsilon (\tau,\delta)$, where $\tau$ is a type predicate with a finite domain, every constant appearing in $\delta$ must be of type $\tau$,
$\delta$ is a basic program without sensing actions, and either $\delta$ is a procedure call itself, or $\delta$ does not contain any procedural call. $\Upsilon (\tau,\delta)$ is executed by
calling a state-of-the-art planner to
generate a sequence of actions constituting a legal execution of program $\delta$ where objects are restricted to elements of type $\tau$.
Thus we require that when executing $\Upsilon(\tau, \delta)$, the agent should have complete knowledge regarding the execution of $\delta$ restricted to $\tau$. We will formalize the latter requirement when we present the implementation of the planning operator.

We assume a local-effect BAT $\at$ such that $\at_{ss}$ is essentially quantifier, $\at_{sf}$ is quantifier-free, and $\at_{S_0}$ is proper$^+$. We call such a BAT well-formed.
In the rest of this paper, we restrict our attention to well-formed BATs.
Following \cite{CL09}, the formal semantics we present here is an adaptation of the single-step transition semantics of \cite{GLL00}. A central concept is that of a configuration, denoted as a pair $(\delta,\sigma)$, where $\delta$ is a program (that remains to be executed) and $\sigma$ a situation (of actions that have been performed). A configuration can be final, which means that the run can successfully terminate in that situation, or it can make certain transitions to other configurations. Our semantics is based on progression, $\SL$-based limited reasoning, and closed-world assumption on knowledge: when we evaluate a test $\phi$ wrt a configuration $(\delta,\sigma)$, we check if $\clo(B_0 \prog(\init,\sigma))\models \phi[\sigma]$. Note that $\phi$ is a situation-suppressed formula, and $\phi[\sigma]$ denotes the formula obtained from $\phi$ by taking $\sigma$ as the situation arguments of all fluents.

For lack of space, we leave out semantics of procedures. Conditionals and loops are defined as abbreviations:

${\bf if} \thickspace \phi\thickspace {\bf then}\thickspace \delta_1\thickspace
{\bf else}\thickspace \delta_2\thickspace {\bf endIf} \overset{def}{=}
[\phi?;\delta_1]\mid [\neg \phi?;\delta_2]$,

${\bf while} \thickspace \phi\thickspace {\bf do}\thickspace \delta\thickspace
{\bf endWhile} \overset{def}{=}[\phi?;\delta]^*; \neg \phi?$.




We first give the formal semantics for basic constructs.
The set of final configurations wrt $\at$, denoted $\FC$, is inductively defined as follows:
\begin{enumerate}
\item $(nil, \sigma)\in \FC$.
\item $(\delta_1; \delta_2, \sigma)\in \FC$ if $(\delta_1, \sigma)\in \FC$ and $(\delta_2, \sigma)\in \FC$.
\item $(\delta_1 \thinspace | \thinspace \delta_2, \sigma)\in \FC$ if $(\delta_1, \sigma)\in \FC$ or $(\delta_2, \sigma)\in \FC$.
\item $(\pi \vec{x}.\phi \wedge \delta, \sigma)\in \FC$ if there exist constants $\vec{c}$ such that $\clo(B_0 \prog(\init,\sigma))\models \phi(\vec{c})[\sigma]$ and $( \delta(\vec{c}), \sigma)\in \FC$.
\item $(\delta^*, \sigma)\in \FC$.
\end{enumerate}

The transition relation between configurations wrt $\at$, denoted $\trans$, is inductively defined as follows:
\begin{enumerate}

\item
$(\alpha, \sigma) \trans (nil, do(\alpha, \sigma))$ if  $\alpha=A(\vec{c})$ is a physical action and $\clo(B_0 \prog(\init,\sigma))\models B_0 \Pi_A(\vec{c},\sigma)$. Recall that the action precondition axiom for $A(\vec{x})$ is
$Poss(A(\vec{x}) \equiv \Pi_A(\vec{x},s)$.

\item $(\alpha, \sigma) \trans (nil, do(\alpha_\mu, \sigma))$ if  $\alpha=A(\vec{c})$ is a sensing action, the sensing result is $\mu$, and $\clo(B_0 \prog(\init,\sigma))\models B_0 \Pi_A(\vec{c},\sigma)$.

\item $(\phi?, \sigma) \trans (nil, \sigma)$ if $\clo(B_0 \prog(\init,\sigma))\models \phi[\sigma]$.

\item
$(\delta_1 ; \delta_2, \sigma) \trans (\gamma; \delta_2, \sigma')$ if $(\delta_1, \sigma) \trans (\gamma, \sigma')$.

\item $(\delta_1 ; \delta_2, \sigma) \trans (\gamma, \sigma') $ if $(\delta_1, \sigma) \in\FC$ and $(\delta_2, \sigma) \trans (\gamma, \sigma')$.

\item $(\delta_1 \thinspace | \thinspace \delta_2, \sigma) \trans (\gamma, \sigma')$ if $(\delta_1, \sigma) \trans (\gamma, \sigma')$ or \\ $(\delta_2, \sigma) \trans (\gamma, \sigma')$.

\item
$(\pi \vec{x}. \phi \land \delta, \sigma) \trans (\gamma, \sigma')$ if there exist constants $\vec{c}$ s.t. $\clo(B_0 \prog(\init,\sigma))\models \phi(\vec{c})[\sigma]$ and $( \delta(\vec{c}), \sigma)\trans (\gamma, \sigma')$.

\item
$(\delta^*, \sigma) \trans (\gamma; \delta^*, \sigma')$ if $(\delta, \sigma) \trans (\gamma, \sigma')$.

\end{enumerate}

To define the semantics of search and planning operators, we define a relation $\CM$: intuitively,
$(\delta,\sigma,\rho)\in \CM$ means that an offline-execution of program $\delta$ in situation $\sigma$ results in conditional program $\rho$. To define $\CM$, we introduce an auxiliary relation $\EX$: intuitively, $(\rho,\delta,\sigma,\rho')\in \EX$ means that in situation $\sigma$, executing conditional program $\rho$ and then program $\delta$, leads to conditional program $\rho'$.
Formally,
$\CM$ is inductively defined as follows:

\begin{enumerate}
\item
$(nil, \sigma, nil) \in \CM$.

\item
$(\alpha, \sigma, \alpha) \in \CM$ if $\alpha$ is $A(\vec{c})$ and $\clo(B_0 \prog(\init,\sigma))\models B_0 \Pi_A(\vec{c},\sigma)$.

\item
$(\phi?, \sigma, nil) \in \CM$ if $\clo(B_0 \prog(\init,\sigma))\models \phi[\sigma]$.

\item
$(\delta_1 ; \delta_2, \sigma, \rho) \in \CM$ if  there exists $\rho'$ such that $(\delta_1, \sigma, \rho')\in \CM$ and $(\rho', \delta_2, \sigma, \rho)\in \EX$.

\item
$(\delta_1\thinspace|\thinspace\delta_2, \sigma, \rho) \in \CM$ if $(\delta_1, \sigma, \rho) \in \CM$ or $(\delta_2, \sigma, \rho)\in \CM$.

\item
$(\pi \vec{x}. \phi \land  \delta, \sigma, \rho )\in \CM$ if there exist constants $\vec{c}$ such that $\clo(B_0 \prog(\init,\sigma))\models \phi(\vec{c})[\sigma]$ and $(\delta(\vec{c}), \sigma, \rho)\in \CM$.

\item $(\delta^*,\sigma,nil)\in \CM$; and $(\delta^*,\sigma,\rho)\in \CM$ if there exists $\rho'$ such that $(\delta^*,\sigma,\rho')\in \CM$ and $(\rho', \delta,\sigma, \rho)\in \EX$.

\end{enumerate}


The formal definition of $\EX$ is as follows:

\begin{enumerate}
\item
$(nil, \delta, \sigma, \rho') \in \EX$ if $(\delta,\sigma,\rho')\in \CM$.

\item
$(\alpha;\rho, \delta, \sigma, \alpha; \rho') \in \EX$ if $\alpha$ is a physical action and  $(\rho, \delta, do(\alpha,\sigma), \rho')\in \EX$.

\item
$(\alpha; \rho, \delta, \sigma, \rho')\in \EX$ if $\alpha$ is a sensing action and there exist $\rho_1$ and $\rho_2$ such that
$(\rho, \delta, do(\alpha_T, \sigma), \rho_1)\in \EX$ and
$(\rho, \delta, do(\alpha_F, \sigma), \rho_2)\in \EX$ and $\rho'$ is: $\alpha;$ \textbf{if} $\Knows\Psi_A(\vec{c})$ \textbf{then} $\rho_1$ \textbf{else} $\rho_2$ {\bf endIf}.
Recall that the sensored fluent axiom for $A(\vec{x})$ is $SF(A(\vec{x}),s)\equiv \Psi_A(\vec{x},s)$.

\item
$($\textbf{if} $\phi$ \textbf{then} $\rho_1$ \textbf{else} $\rho_2$ {\bf endIf}$, \delta,\sigma, \rho) \in \EX$ if the following holds: if $\clo(B_0 \prog(\init,\sigma))\models \phi[\sigma]$, then
$(\rho_1,\delta, \sigma, \rho) \in \EX$, otherwise $(\rho_2, \delta, \sigma, \rho) \in \EX$.

\end{enumerate}

To define the semantics of $\Upsilon (\tau,\delta)$, we define the restriction of $\delta$ to $\tau$, denoted by $\delta_\tau$. Intuitively, $\delta_\tau$ is $\delta$ where objects are restricted to elements of type $\tau$. Formally, $\delta_\tau$ is obtained from $\delta$ as follows: replace each formula of the form $\forall x \phi$ with $\forall x. \Knows\tau(x) \limp \phi$, and $\exists x \phi$ with $\exists x. \Knows\tau(x) \land \phi$, and replace each construct of the form $\pi \vec{x}.\phi \land \delta$ with $\pi \vec{x}.\bigwedge \Knows\tau(x_i) \land \phi \land \delta$. We require that the initial KB $\at_{S_0}$ contains a sentence of the form $\forall x. \tau(x) \equiv x = d_1 \vee \ldots \vee x=d_n$.

We can now expand the definition of the transition relation with the following items:
\begin{enumerate}
\item[8.]
$(\Sigma \delta, \sigma) \trans (\rho, \sigma)$ if $(\delta,\sigma,\rho)\in\CM$.

\item[9.]
$(\Upsilon (\tau,\delta), \sigma) \trans (\rho, \sigma)$ if $(\delta_\tau,\sigma,\rho)\in\CM$.
\end{enumerate}


Finally, an online execution of a LBGolog program $\delta_0$ starting from a situation $\sigma_0$ is a sequence of configurations
$(\delta_0, \sigma_0), \ldots, (\delta_n, \sigma_n)$, such that for $i<n$, $(\delta_i, \sigma_i)\trans (\delta_{i+1}, \sigma_{i+1})$. The online execution is successful if $(\delta_n, \sigma_n)\in \FC$.

We now illustrate programming in LBGolog with the Wumpus World \cite{wumpus}. Below is the main program, where $n_1$ is a constant for coordinate 1. The agent first senses the environment. If she knows that the gold is at location $(1,1)$, she grabs the gold and climbs out of the dungeon. Otherwise, she explores the dungeon, moves to location $(1,1)$ by use of the planning operator, and climbs out.

\noindent $\textbf{proc}\quad main\\
\indent sense\_stench; sense\_breeze; sense\_gold;\\
\indent\textbf{if}\thickspace \Knows(gold(n_1,n_1))
\thickspace\textbf{then}\thickspace grab; climb\\
\indent\textbf{else} \thickspace explore; \Upsilon moveLoc(n_1,n_1); climb \indent \textbf{endIf} \\
\textbf{endProc}$

The following procedure moves to location $(X,Y)$ by traversing only visited locations. Here $agt(x,y)$ means that
the agent is at location $(x,y)$.

\noindent $\textbf{proc}\quad moveLoc(X,Y)\\
\indent [ \pi x_0,y_0,x_1,y_1. \Knows(agt(x_0,y_0) \wedge explored(x_1,y_1))\\
\indent\indent  \wedge move(x_0,y_0,x_1,y_1) ]^*;\\
\indent\pi x_2,y_2. \Knows(agt(x_2,y_2)) \wedge move(x_2,y_2,X,Y) \\
\textbf{endProc}$

The procedure below explores the dungeon. Here $wp(x,y)$ means that the wumpus is at location $(x,y)$. While the agent knows she has not got the gold, she picks an unvisited safe location, moves there, and senses the environment. If she knows the gold is at her location, she grabs the gold. Otherwise, if she knows that the wumpus is alive and she knows the location of the wumpus, she shoots the wumpus.


\noindent$\textbf{proc}\quad explore\\
\indent\textbf{while}\quad \Knows(\neg getsGold) \wedge\\
\indent\exists x,y. \Knows((\neg wp(x,y) \vee \neg wpAlive) \wedge \neg pit(x,y)) \wedge\\
\indent\indent\indent\indent\neg \Knows(explored(x,y)) \quad \textbf{do}\\
\indent \pi x,y. \Knows((\neg wp(x,y) \vee \neg wpAlive) \wedge \neg pit(x,y)) \wedge\\
\indent\indent\indent\indent\neg \Knows(explored(x,y)) \wedge\\
\indent\indent\indent\Upsilon moveLoc(x,y);  \\
\indent\indent\indent sense\_stench; sense\_breeze; sense\_gold;\\
\indent\indent\indent\textbf{if}\quad \Knows(\exists x_0,y_0. agt(x_0,y_0) \wedge gold(x_0,y_0))\\
\indent\indent\indent\textbf{then}\quad grab \quad \textbf{else}\\
\indent\indent\indent\indent\textbf{if}\quad \exists x_1,y_1.\Knows(wpAlive \wedge wp(x_1,y_1))\\
\indent\indent\indent\indent\textbf{then}\quad shootWumpus\indent\textbf{endIf}
\thickspace \textbf{endIf} \thickspace \textbf{endWhile}\\
\textbf{endProc}$

 Finally, the procedure for shooting the wumpus. Here $succ(x,y)$ means that $y$ is the successor coordinate of $x$. The agent picks an explored location $(x_2,y_2)$ which is adjacent to the wumpus' location, moves to $(x,y)$, shoots and senses if there is a scream.

\noindent $\textbf{proc}\quad shootWumpus\\
\indent[\pi x_1,y_1,x_2,y_2.\Knows(wp(x_1,y_1) \wedge explored(x_2,y_2) \wedge \\
\indent\indent(x_1=x_2 \wedge succ(y_1,y_2)) \vee (x_1=x_2 \wedge succ(y_2,y_1))\\
\indent\indent(y_1=y_2 \wedge succ(x_1,x_2)) \vee (y_1=y_2 \wedge succ(x_2,x_1))) \wedge \\
\indent\indent \Upsilon moveLoc(x_2,y_2);\\
\indent\indent(succ(y_2,y_1)?;shoot\_up \thinspace | \thinspace succ(y_1,y_2)?;shoot\_down \thinspace |\\
\indent\indent succ(x_1,x_2)?;shoot\_left\thinspace | \thinspace succ(x_2,x_1)?;shoot\_right)];\\
\indent sense\_scream\\
\textbf{endProc}$

\section{Implementing progression and query evaluation by grounding}

As shown in the last section, to implement LBGolog, we need to implement progression and evaluation of a $\SL$ formula against the closure of $B_0 \at_\sigma$, where $\at_\sigma$ is the current KB. Initially, we implemented the progression algorithm from \cite{LL09} and the query evaluation algorithm from (LLL04). However, the implementation was not efficient. So we decided to implement progression and query evaluation by grounding. But we have an infinite domain. The trick is to use an appropriate number of special constants as representatives of those infinitely many constants not mentioned by the KB.

Here is the general picture. We first ground the initial KB, perform unit propagation on it. When an action is performed, if the action mentions new constants, we extend the current ground KB with these constants, then we progress the ground KB, and perform unit propagation on it. Whenever we need to evaluate a query, we use the current ground KB to answer the query. In the following, we present grounding, progression, and query evaluation in sequence.

\subsection{Grounding}

We begin with initial grounding.
We define the width of a proper$^+$ KB $\Sigma$ as the maximum number of distinct variables in a $\forall$-clause of $\Sigma$. Let $j$ be the width of $\Sigma$.
To simplify presentation, we assume that there are $j$ reserved constants $u_1, \ldots, u_j$: they do not appear in the initial KB and will not be mentioned by any action. We let $U$ denote the set of these constants, and call constants not in $U$ normal constants. For a set $\Gamma$ of formulas, we use $H(\Gamma)$ to denote the set of normal constants appearing in $\Gamma$, and let $H^+(\Gamma)$ represent
$H(\Gamma)$ extended with a normal constant not appearing in $\Gamma$.

\begin{definition}
Let $\Sigma$ be a proper$^+$ KB with width $j$.
Let $N$ be a set of normal constants containing those appearing in $\Sigma$.
We define $prop(\Sigma, N)$ as the set of those clauses of $\gnd(\Sigma)$ which uses only constants from $N$ or $U$.
\end{definition}

The intuition is that constants not appearing in $\Sigma$ behave the same, and we take U constants as their representatives.
In the sequel, we let $\Sigma_p$ denote a ground \properplus\ KB with U constants. To prove correctness of grounding, we first define the first-order KB represented by $\Sigma_p$.

\begin{definition} We define $FO(\Sigma_p)$ as follows: replace each $c$ in $\Sigma_p$ with $FO(c)$, denoting $\forall (e \supset c(u_1/x_1, \ldots, u_{j}/x_{j}))$, where $e$ is the ewff $\bigwedge^j_{i = 1}x_i\not\in H(\Sigma_p) \wedge \bigwedge_{i \neq k}x_i \neq x_k$, and $x\not \in N$ is the abbreviation for $\bigwedge_{d\in N}x\neq d$.
\end{definition}

Let $\Gamma_1$ and $\Gamma_2$ be two sets of sentences. We write $\Gamma_1 \Eequiv \Gamma_2$ if $\Eaxiom \cup \Gamma_1 \models \Gamma_2$ and $\Eaxiom \cup \Gamma_2 \models \Gamma_1$.


\begin{theorem} \label{gnd-thm} $FO(prop(\Sigma, N)) \Eequiv \Sigma$.
\end{theorem}

We now define extended grounding.

\begin{definition} \label{extend-ground-def}
Let $B$ be a finite set of normal constants s.t. $B \cap H(\psig) = \emptyset$. We define $egnd(\Sigma_p,B)$ inductively as follows:
\begin{enumerate}
\item $egnd(\Sigma_p, \emptyset) = \Sigma_p$;
\item $egnd(\Sigma_p, \{d\}) = \Sigma_p \cup \{c(u_k/d)\mid c\in \Sigma_p, 1\leq k\leq j\}$;
\item $egnd(\Sigma_p, \{d\} \cup B) = egnd(egnd(\Sigma_p, \{d\}), B)$.
\end{enumerate}
\end{definition}

The following shows correctness of extended grounding.

\begin{theorem}\label{egnd-thm}
$egnd(prop(\Sigma, N), B)\Eequiv prop(\Sigma,N\cup B)$.
\end{theorem}

Note that the way we do grounding is brute-force. For example, if $\Sigma$ contains $\forall x P(x)$, then its ground KB contains $P(u_1), \ldots, P(u_j)$, each of which carries the same information. However, brute-force grounding will facilitate later progression operation.

\subsection{Progression}

We now define progression of a ground KB, and show that it is equivalent to progression of the original KB. Recall the notation from the background work section on progression.

\begin{definition} Let $\at$ be a well-formed BAT, and $\alpha=A(\vec{c})$ a ground action.
Let $B$ be the set of constants appearing in $\vec{c}$ but not $\Sigma_p$. We define $pprog(\Sigma_p, \alpha)$ as
\[forget(egnd(\Sigma_p, B) \cup \mathcal{D}_{ss}(\Omega), \Omega(S_0))(S_0/\Sa),\]
if $\alpha$ is a physical action, and $ \Sigma_p(S_0/\Sa) \cup (\neg) \Psi_A(\vec{c},S_\alpha)$ if $\alpha$ is a sensing action.
\end{definition}
Forgetting a ground atom $q$ from a set of ground clauses can be done by computing all resolvents wrt $q$ and then removing all clauses containing $q$. The following lemma establishes connection between forgetting a ground atom from a proper$^+$ KB $\Sigma$ and from its ground KB.

\begin{lemma}\label{gnd-forget-fo}
Let $q$ be a ground atom. Let $N$ be a set of normal constants containing those that appear in $\Sigma$ or $q$.
Then $forget(\Sigma, q) \Eequiv FO(forget(prop(\Sigma, N), q))$.
\end{lemma}

By Theorems \ref{prog-thm}, \ref{gnd-thm}, \ref{egnd-thm} and Lemma \ref{gnd-forget-fo}, we have

\begin{theorem} \label{pprog-thm}
$FO(pprog(prop(\Sigma, N), \alpha)) \Eequiv prog(\Sigma, \alpha) $.
\end{theorem}


\subsection{Query Evaluation}

We say that a query $\phi$ is suitable for $\Sigma_p$ if for each clause $c$ in $\phi$, the total number of variables in $c$ and constants in $c$ but not $\Sigma_p$ is no more than the number of $U$ constants in $\Sigma_p$.

 We first define an evaluation procedure $G[\Sigma_p, \phi]$, where $\phi\in \Lan$ is suitable for $\Sigma_p$. It is the same as the $W[\Sigma,k,\phi]$ procedure from (LLL04) where $k=0$ except for the case of evaluating clauses.
\begin{displaymath}
G[\Sigma_p, \phi] = \left\{ \begin{array}{ll}
1 & \textrm{if one of the following conditions holds.}\\
0 & \textrm{otherwise.}
\end{array} \right.
\end{displaymath}
\begin{enumerate}
\item $\phi$ is a clause $c$ and there exists a clause $c' \in \UP{\Sigma_p}$ such that $c' \subseteq c(d_1/u_1,\ldots,d_k/u_k)$, where $\{d_1,\ldots,d_k\}$ is the set of normal constants that appear in $c$ but not $\Sigma_p$.

\item $\phi = (d = d')$ and $d$ is identical to $d'$.

\item $\phi = (d \neq d')$ and $d$ is distinct from $d'$.

\item $\phi = \neg \neg \psi$ and $G[\Sigma_p, \psi] = 1$.

\item $\phi = (\psi \vee \eta)$, $\psi$ or $\eta$ is not a clause, \\and $G[\Sigma_p, \psi] = 1$ or $G[\Sigma_p, \eta] = 1$.

\item $\phi = \neg (\psi \vee \eta)$, $G[\Sigma_p, \neg \psi] = 1$ and $G[\Sigma_p, \neg \eta] = 1$.

\item $\phi = \exists x\psi$ and $G[\Sigma_p, \psi^x_d]\! = \!1$ for some $d \!\in\! H^+(\psig \cup  \{\psi\})$.

\item $\phi = \neg \exists x\psi$ and $G[\Sigma_p, \neg\psi^x_d]$ for all $d \in H^+(\psig \!\cup \!\{\psi\})$.
\end{enumerate}



Based on $G$, we now define an evaluation procedure $F[\Sigma_p, \varphi]$, where $\varphi \in \SL_0$ is suitable for $\Sigma_p$.
\begin{displaymath}
F[\Sigma_p, \varphi] = \left\{ \begin{array}{ll}
1 & \textrm{if one of the following conditions holds.}\\
0 & \textrm{otherwise.}
\end{array} \right.
\end{displaymath}
\begin{enumerate}
\item $\varphi= B_{0}\phi$ and $G[\Sigma_p, \phi] = 1$.

\item $\varphi = (t_1 = t_2)$ and $t_1$ is identical to $t_2$.

\item $\varphi = \neg \omega$ and $F[\Sigma_p, \omega] = 0$.

\item $\varphi = \varphi_1 \vee \varphi_2$, and $F[\Sigma_p, \varphi_1] = 1$ or $F[\Sigma_p, \varphi_2] = 1$.

\item $\varphi \!= \!\exists x \omega$, and $F[\Sigma_p, \omega^x_d]\! = \!1$ for some $d \! \in \! H^+(\psig \cup \{\omega\})$.
\end{enumerate}

By exploiting that U constants serve as representatives of constants not appearing in $\Sigma_p$, we can prove

\begin{lemma}\label{F-lem}
$F[\Sigma_p, \varphi] = 1$ iff $\gnd( FO(\Sigma_p)) \models \varphi$.
\end{lemma}

By Lemma \ref{F-lem} and Theorem \ref{bcl-thm}(3), we have

\begin{theorem}\label{F-thm}
$F[\Sigma_p, \varphi] = 1$ iff $\clo(B_0 FO(\Sigma_p)) \models \varphi$.


\end{theorem}



\section{An interpreter}

We have implemented an interpreter for \emph{$\mathcal{LB}$Golog} in Prolog.
We assume the user provides the following set of clauses corresponding to the background basic action theory:

\begin{itemize}
\item \texttt{init\_kb}$(l)$: $l$ is a list of $\forall$-clauses of the initial KB;

\item \texttt{poss}$(\alpha,\phi)$: formula $\phi$ is the precondition for action $\alpha$;

\item \texttt{ssa}$(F,\gamma^+,\gamma^-)$: $\gamma^+$ is the condition for making $F$ true, and $\gamma^-$ is the condition for making $F$ false;

\item \texttt{sf}$(\beta,\phi)$: $\beta$ senses whether $\phi$ holds.
\end{itemize}


Since progression and query evaluation are the most frequent operations during the execution of the interpreter, to improve efficiency, we implement the core parts of the two operations in C, and provide the following primitive predicates in Prolog:

\begin{itemize}

\item \texttt{query}$(\phi,s)$: evaluate  formula $\phi$ in situation $s$;

\item \texttt{query}$($\texttt{what}$(\vec{c}, \vec{x}, \phi), s)$: return $\vec{c}$ such that subjective formula $\phi_{\vec{c}}^{\vec{x}}$ is evaluated true in situation $s$;

\item \texttt{prim\_prog}$(\alpha,s,s')$: progress the KB of situation $s$ to situation $s'$ wrt primitive action $\alpha$;

\item \texttt{sens\_prog}$(\beta,r,s,s')$: progress the KB of situation $s$ to situation $s'$ wrt sensing action $\beta$ with sensing result $r$;

\item \texttt{del\_sit($s$)}: delete the KB about situation $s$.

\end{itemize}
All KBs are stored as data structures in \emph{C}. The two progression operators yield the new KBs while keeping the old ones. Thus we need the \texttt{del\_sit} predicate.

In the following, we present the implementation of the basic constructs, search and planning operators in sequence,
and end with correctness theorems of the interpreter.

\subsection{Basic constructs}

We define predicates \texttt{btrans/3} and \texttt{bfinal/1} to implement the ${\cal F}$ and $\rightarrow $ relations in the semantic definition. Note that we omit the current situation $\sigma_c$ from the arguments. Thus \texttt{bfinal}$(\delta)$ represents $(\delta,\sigma_c)\in {\cal F}$, and
\texttt{btrans}$(\delta, \delta', \alpha)$ means $(\delta,\sigma_c) \trans (\delta',do(\alpha,\sigma_c))$. The Prolog syntax for the constructs are: \texttt{E1:E2} for sequence, \texttt{E1\#E2} for nondet. choice; \texttt{pi(L,G,E)} for guarded nondet. choice of arguments, \texttt{star(E)} for nondet. iteration, \texttt{A} for primitive action, and \texttt{B} for sensing action. For illustration, we present only some of the clauses. We use predicate \texttt{subl}$(l_x, l_c, p_x, p_c)$ to substitute all variables of $l_x$ occurring in program $p_x$ with corresponding constants of $l_c$, resulting in program $p_c$.

\begin{verbatim}
bfinal(nil).
bfinal(E1:E2):-bfinal(E1),bfinal(E2).
bfinal(E1#E2):-bfinal(E1);bfinal(E2).
bfinal(pi(L,G,E)):-query(what(L1,L,G)),
    subl(L,L1,E,E1),bfinal(E1).
bfinal(star(_)).
bfinal(E):-proc(E,E1),bfinal(E1).

btrans(A,nil,A):-prim_action(A),
    poss(A,P),query(knows(P)).
btrans(?(P),nil,nil):-query(P).
btrans(E1:E2,E,A):-btrans(E1,E3,A),
    E=(E3:E2);bfinal(E1),btrans(E2,E,A).
btrans(star(E),E1:star(E),A):-
    btrans(E,E1,A).
\end{verbatim}

The top part of the interpreter uses \texttt{btrans} and \texttt{bfinal} to determine the next action to perform or to terminate. To perform an action, do the corresponding input/output actions, and then do progression. Predicate \texttt{curr\_sit}$(s)$ maintains the current situation, and
\texttt{update\_sit}$(s)$ updates the current situation and deletes the KB of the old situation.
\begin{verbatim}
lbGolog(E):-btrans(E,E1,A),
    (A=nil->true;do(A)),!,lbGolog(E1).
lbGolog(E):-bfinal(E),!.

do(A):-execute(A),prim_prog(A).
do(B):-execute(B,R),sens_prog(B,R).
execute(A):-prim_action(A),writeln(A).
execute(B,R):-sens_action(B),write(B),
    write(':(y/n)'),read(R).

query(P):-curr_sit(S),query(P,S).
prim_prog(A):-curr_sit(S),
    prim_prog(A,S,S1),update_sit(S1).
sens_prog(B,R):-curr_sit(S),
    sens_prog(B,R,S,S1),update_sit(S1).
update_sit(S):-retract(curr_sit(S0)),
    del_sit(S0),assert(curr_sit(S)).
\end{verbatim}


\subsection{Search operator $\Sigma$}

We define predicates $bdo/3$ and $ext/4$ to implement relations $\mathcal{C}$ and $\mathcal{E}$ respectively. We present only some of the clauses. Note that when implementing search, we explore a tree of situations, and maintain KBs of different situations. Once search succeeds or backtracks, we delete KBs accordingly.
\begin{verbatim}
bdo(B,S,B):-sens_action(B),poss(B,P),
    query(knows(P),S).
bdo(E1:E2,S,C):-bdo(E1,S,C1),
    ext(C1,E2,S,C).
bdo(star(E),S,C):-C=nil;bdo(E,S,C1),
    ext(C1,star(E),S,C).

ext(nil,E,S,C):-bdo(E,S,C).
ext(A:C,E,S,A:C1):-prim_action(A),
    prim_prog(A,S,S1),(ext(C,E,S1,C1),
    del_sit(S1);del_sit(S1),fail).
ext(B:C,E,S,C1):-sens_action(B),
    sens_prog(B,1,S,ST),(ext(C,E,ST,CT),
    del_sit(ST);del_sit(ST),fail),
    sens_prog(B,0,S,SF),(ext(C,E,SF,CF),
    del_sit(SF);del_sit(SF),fail),
    sf(B,F),C1=(B:if(knows(F),CT,CF)).
ext(if(P,C1,C2),E,S,C):-query(P,S)->
    ext(C1,E,S,C);ext(C2,E,S,C).
\end{verbatim}
Then the \texttt{btrans} clause for the search operator is:
\begin{verbatim}
btrans(search(E),E1,nil):-curr_sit(S),
    bdo(E,S,E1).
\end{verbatim}

The implementation of the search operator ensures that nondeterministic choices are resolved in a way that guarantees the successful completion of the program. To see an example, consider the program
$\delta$ below for catching a plane:

\noindent
$sense\_gate\_A;buy\_paper;\\
(goto(gate\_A);buy\_coffee \thinspace | \thinspace buy\_coffee;goto(gate\_B));\\
board(plane)$\\
Assume that there are only two gates $A$ and $B$, and $sense\_gate\_A$ tells the agent which gate to take. Note that $board(plane)$ is executable only if the agent gets to the right gate. So an online execution of $\delta$ might not be successful.
This problem can be solved by using the search operator. The interpretation of $\Sigma\delta$ results in the following program, whose online execution is guaranteed to be successful.

\noindent
$sense\_gate\_A;\\
\textbf{if}\; \Knows(it\_is\_gate\_A)\\
\textbf{then}\; buy\_paper;goto(gate\_A);buy\_coffee;board(plane)\\
\textbf{else}\; buy\_paper;buy\_coffee;goto(gate\_B);board(plane)$,\\


\subsection{Planning operator $\Upsilon$}
The main idea of our implementation of the planning operator $\Upsilon(\tau,\delta)$ is this: we construct a planning instance from the BAT $\at$, $\tau$ and $\delta$, and call an existing planner to solve the instance. Our implementation is based the work by \cite{BFM07} on compiling procedural domain control knowledge written in a Golog-like program into a planning instance.

A planning instance is a pair $I=(D,P)$, where $D$ is a domain definition and $P$ is a problem. We assume that $D$ and $P$ are described in ADL. A domain definition consists of domain predicates and functions, operators, and domain objects. A problem consists of an initial state and a goal. An operator is a tuple $\langle O(\vec{x}), Pre(\vec{x}), Eff(\vec{x})\rangle$, where $O(\vec{x})$ is the operator name, $Pre(\vec{x})$ is the precondition axiom, and $Eff(\vec{x})$ is a list of conditional effect axioms. Not that quantifiers are allowed in the axioms.

Baier \etc define a translating function which, given a planning instance $I$ and a program $\delta$, outputs a new instance $I_\delta$ such that planning for the generated instance $I_\delta$ is equivalent to planning for the original instance $I$ under the control of $\delta$, except that plans for $I_\delta$ contain some auxiliary actions.

We now present a translation function which, given a well-formed BAT $\at$, a program $\Upsilon(\tau, \delta)$ and a ground situation $\sigma$, outputs a planning instance $I$.
Since $\at$ is local-effect, for any action $A(\vec{x})$, we can generate an ADL operator $O(A(\vec{x}))=\langle A(\vec{x}), Pre(\vec{x}), Eff(\vec{x}) \rangle$, where $Pre(\vec{x})$ is directly obtained from the action precondition axiom, and $Eff(x)$ is obtained from the SSAs. We omit the details here.
We use ${\cal P}_{\at}(\delta)$ to denote the set of predicates relevant to program $\delta$ wrt BAT $\at$, that is, the set of predicates that occur in tests of $\delta$ or precondition or effect axioms
for actions that occur in $\delta$.


\begin{definition} \label{translate} {\bf (Translation function $\TR$)}
Given a well-formed BAT $\mathcal{D}$, a program $\Upsilon(\tau, \delta)$ and a ground situation $\sigma$, we define a planning instance $I$ as follows:
\begin{enumerate}
  \item the domain predicates are elements of ${\cal P}_{\mathcal{D}}(\delta)$;

  \item the operations are $O(A(\vec{x}))$ where $A$ appears in $\delta$;

  \item the objects are elements of the type predicate $\tau$;

  \item the initial state consists of ground atoms $P(\vec{c})\in \UP{\at_\sigma}$ s.t. $P \in {\cal P}_{\mathcal{D}}(\delta)$, $\vec{c}\in \tau$ and $\at_\sigma$ is the KB of $\sigma$.
  \item the goal is $true$.
\end{enumerate}
\end{definition}
To prove property of $\TR$, we define a just-in-time assumption:
\begin{definition}
We say that a ground situation $\sigma$ is just-in-time for $\Upsilon(\tau,\delta)$ wrt $\at$,
if for every ground atom $P(\vec{c})$ such that $P \in {\cal P}_{\mathcal{D}}(\delta)$ and  $\vec{c}\in \tau$,
$ B_0 prog(\at_{S_0},\sigma)\models B_0 P(\vec{c}) $ or $ B_0 prog(\at_{S_0},\sigma)\models B_0 \neg P(\vec{c}) $.
\end{definition}

Let $\delta$ be a program. We define its objective program, denoted by $\delta_o$, as the program obtained from $\delta$ by replacing each test with its objective formula.
The semantics of LBGolog corresponds to that of the Golog-like language by Baier \etc\ except that we apply $\SL$-based reasoning to tests and they evaluate tests wrt databases.
However, under the just-in-time assumption, by a generalize version of Theorem \ref{comp-thm}, $\SL$-based reasoning coincides with database query evaluation.
So we get (Recall that $\delta_\tau$ denotes the restriction of $\delta$ to $\tau$.)

\begin{lemma}\label{plan-lem} Suppose $\sigma$ is just-in-time for $\Upsilon(\tau, \delta)$ wrt $\at$. Then
$(\delta_\tau,\sigma, \rho) \in \CM$ iff $\rho$ is a plan for $I=\TR(\at,\tau,\delta, \sigma)$ under control of $\delta_o$.
\end{lemma}

We implement a predicate \texttt{plan}$(\tau, \delta, \sigma, \delta')$ which does the following: First, apply $\TR$ on $(\at,\tau,\delta,\sigma)$ to generate a planning instance $I$.
Then apply Baier \etc\'s translation (with a slight modification) on $(I,\delta_o)$ to obtain a planning instance $I'$, call FF planner \cite{FF} on $I'$ to get a plan $\rho$. Finally, filter out the auxiliary actions from $\rho$.
Then the \texttt{btrans} clause for the planning operator is:
\begin{verbatim}
btrans(planning(T,E),E1,nil):-
    curr_sit(S),proc(E,E2)->
    plan(T,E2,S,E1);plan(T,E,S,E1).
\end{verbatim}

Actually, the domain part of the planning instance $I'$ does not depend on the current situation, and is generated during preprocessing of the program. Only the problem part is generated each time $\Upsilon(\tau, \delta)$ is called.

\subsection{Correctness of the interpreter}


Due to correctness of progression and query evaluation (Theorems \ref{pprog-thm} and \ref{F-thm}), by induction on the program,
it is easy to prove the following two theorems:

\begin{theorem}\label{structures theorem}
{\bf (Correctness of basic constructs)} Let $\at$ be a well-formed BAT, $\delta$ a basic program, and $\sigma$ a ground situation. Then
\begin{enumerate}
\item {\em bfinal}($\delta$) wrt $\sigma$ succeeds  iff $(\delta, \sigma)\in \FC$;
\item if {\em btrans}($\delta$, $P$, $A$) wrt $\sigma$ succeeds with $P = \delta'$ and $A = \alpha$, then $(\delta,\sigma) \trans (\delta', do(\alpha, \sigma))$, where $do(nil,\sigma)=\sigma$;
\item if $(\delta,\sigma) \trans (\delta', \sigma')$, then {\em btrans}($\delta$, $P$, $A$) wrt $\sigma$ succeeds.
\end{enumerate}
\end{theorem}

\begin{theorem}\label{search theorem} {\bf (Soundness and weak completeness of search)}
Let $\at$ be a well-fromed BAT, $\delta$ a basic program, and $\sigma$ a ground situation. Then we have
\begin{enumerate}
\item if {\em btrans}(search($\delta$), $P$, $A$) wrt $\sigma$ succeeds with $P = \delta'$, then $(\delta, \sigma, \delta')\in\CM$;

\item
 if $(\delta, \sigma, \delta')\in\CM$ for some $\delta'$, then
{\em btrans}({\em search}($\delta$), $P$, $A$) wrt $\sigma$ succeeds or does not terminate.
\end{enumerate}
\end{theorem}

To see why we get weak completeness, consider  program $\delta= (\alpha^*;false?) \thinspace  | \thinspace true?$. Although
$(\delta,\sigma,nil)\in \CM$, to search $\delta$, we first search $\alpha^*;false?$ and would not terminate.

The theorem below follows from Lemma \ref{plan-lem}:

\begin{theorem}\label{planning theorem} {\bf (Correctness  of planning operator)}\\
Suppose $\sigma$ is just-in-time for $\Upsilon(\tau,\delta)$ wrt well-formed BAT $\at$. Then
\begin{enumerate}
\item if {\em btrans}({\em planning}($\tau, \delta$), $P$, $A$) wrt $\sigma$ succeeds with $P = \delta'$, then
   $(\delta_\tau, \sigma, \delta')\in\CM$;
\item if $(\delta_\tau, \sigma, \delta')\in\CM$ for some $\delta'$, then {\em btrans}({\em planning}($\tau, \delta$), $P$, $A$) wrt $\sigma$ succeeds.
\end{enumerate}
\end{theorem}

\section{Experiments}
We have experimented our interpreter with Wumpus world, blocks world, Unix domain, and service robot domains. Here we present experimental data about Wumpus world
and give an example execution of a program in the blocks world.

\subsection{Wumpus world}

We have written a control program for Wumpus world and executed it with our interpreter. When writing the program, we take a cautious strategy and ensure that the agent gets out the dungeon alive. We assume that there is only one piece of gold. On the premise of safety, the program would control the agent to get the gold as much as possible. Table 1 shows the experiment results for 8$\times$8 maps. Each row represents a setting, and for each setting, we tested our control program on 3000 random maps.

\small\noindent
\begin{center}

\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
Prob & Gold & IMP & Reward & Moves & Time & Calls \\
\hline
10\% & 1412 & 695 & 437 & 34 & 0.398 & 16 \\
\hline
15\% & 890 & 917 & 275 & 22 & 0.246 & 11 \\
\hline
20\% & 567 & 1171 & 175 & 14 & 0.147 & 7 \\
\hline
30\% & 263 & 1581 & 82 & 6 & 0.070 & 3 \\
\hline
40\% & 182 & 1924 & 58 & 3 & 0.040 & 2 \\
\hline
\end{tabular}
Table 1. Experimental results for Wumpus world (8$\times$8, 3000)
\end{center}
\normalsize

In Table 1, \emph{Prob} is the probability of a location containing a pit; \emph{Gold} is the number of maps where the agent got the gold;
\emph{IMP} is the number of maps for which it is impossible to get the gold, that is, the agent sensed smell or stench at the initial location.
The rest of the columns show the average of the reward, the number of moves, the running time in seconds, and the number of calling the FF planner.

As the probability goes up, \emph{IMP} goes up, but all the other indexes go down. In other words, the lower the probability is, the more likely it is for the agent to explore the dungeon and get the gold. Note that, even for the lowest probability, the average running time is less than 0.4 seconds, which shows the efficiency of our interpreter.

\subsection{Blocks World}

In this domain we assume a number of blocks on or above the table, and the goal of the agent is to make clear some of them.
The only primitive action is $move(x, y, z)$, moving block $x$ from the top of $y$ to the top of $z$.
There are 2 fluents: $clear(x)$, denoting that there are no blocks on top of $x$, and $on(x, y)$, denoting that $x$ is on top of $y$.

The relevant axioms as below:

\vspace*{.1cm}
\noindent $Poss(move(x, y, z), s)\equiv on(x, y) \wedge clear(x) \wedge clear(y)$,

\noindent $Poss(sense\_on(x, y), s) \equiv true$,

\noindent $Poss(sense\_clear(x), s) \equiv true$,

\noindent $clear(x,do(a,s))\equiv (\exists y)a=moveToTable(y,x)\vee\\
\hspace*{2cm} clear(x,s)$,

\noindent $on(x,y,do(a,s))\equiv (\exists z)a=move(x, z, y) \vee\\ \hspace*{2cm} on(x,y,s) \wedge (\neg\exists z)a = move(x, y, z)$,

\noindent $SF(sense\_on(x, y), s) \equiv on(x, y, s)$.

The initial KB is as follows:

\vspace*{.1cm}
\noindent $\forall x.x \neq a \wedge x \neq b \wedge x \neq c \wedge x \neq d \supset clear(x)$,

\noindent $\forall x,y.x \neq a \wedge x \neq b \wedge x \neq c \wedge x \neq d \wedge x \neq y \supset \neg on(x, y)$,

\noindent $\forall x, y. x \neq y \supset (on(x, y) \supset \neg clear(y))$,

\noindent $\forall x. \neg on(x, x)$,

\noindent $\forall x, y.x \neq y \supset (on(x, y) \supset \neg on(y, x))$,

\noindent $\forall x, y, z.y \neq z \supset \neg(on(x, y) \wedge on(x, z))$,

\noindent $\forall x, y, z.y \neq z \supset \neg(on(y, x) \wedge on(z, x))$.

\noindent Note that 4 blocks \verb"a", \verb"b", \verb"c" and \verb"d" appear in the initial KB.

The program is as below:
\vspace{.1cm}

\noindent\textbf{proc} $make\_clear\_all(L)$\\
\noindent\textbf{if} $\neg$$\forall b_1.$\Knows($b_1 \in L$)$\supset\Knows(clear(b_1))$\\
\textbf{then} $\pi b_2.\Knows(b_2 \in L)$$\wedge$$\neg\Knows(clear(b_2))$\\
\hspace*{1.2cm}$\wedge$$(make\_clear(b_2, L)$;$make\_clear\_all(L))$ \textbf{endIf}\\
\noindent\textbf{endProc}

\vspace{.1cm}

\noindent\textbf{proc} $make\_clear(x, L)$\\
\noindent\textbf{if} $\neg$\textbf{kwhether}$(clear(x))$ \textbf{then} $sense\_clear(x)$ \textbf{endIf};\\
\noindent\textbf{if} $\neg\Knows(clear(x))$ \textbf{then} \\
\hspace*{0.5cm}\textbf{if} $\exists b_1$.\Knows$(on(b_1, x))$\\
			\hspace*{0.5cm}\textbf{then}  $\pi b_2$.\Knows($on(b_2, x))$\\
\hspace*{1.5cm}$\wedge$$(make\_clear(b_2, L) ; move\_away(b_2, x, L))$\\
\hspace*{0.4cm} \textbf{else} $\pi b_3$.$\neg$\textbf{KWhether}($on(b_3, x))$\\
\hspace*{1.5cm}$\wedge$$(sense\_on(b_3, x) ; make\_clear(x, L)
			)
		$ \textbf{endIf}\\
\noindent \textbf{endIf}\\
\textbf{endProc}

\vspace{.1cm}

\noindent \textbf{proc} $move\_away(y, x, L)$\\
\noindent \textbf{if} $\exists$$b_1$.\Knows($y \neq b_1 \wedge clear(b_1) \wedge b_1\not\in L$)\\
\noindent \textbf{then} $\pi$$b_2.$\Knows($y \neq b_2 \wedge clear(b_2) \wedge b_2\not\in L)$\\
\hspace*{1.3cm}$\wedge$$move(y, x, b_2)$\\
\noindent\textbf{else} $\pi$$b_3$.\Knows$(b_3 \not\in L)$$\wedge$$\neg$\textbf{KWhether}$(clear(b_3))$\\
\hspace*{1.3cm}$\wedge$$(sense\_clear(b_3) ; move\_away(y, x, L))$ \textbf{endIf}\\
\noindent \textbf{endProc}

An example execution is given below:
\begin{verbatim}
?- lbGolog(make_clear_all([a, b, c, d])).
sense_clear(a):no.
sense_on(b,a):no.
sense_on(c,a):no.
sense_on(d,a):yes.
sense_clear(d):no.
sense_on(b,d):no.
sense_on(c,d):yes.
sense_clear(c):yes.
move(c,d,c1)
move(d,a,c2)
sense_clear(b):yes.
true.
\end{verbatim}

Note how clever our agent is.
Having discovered that \verb"c" is clear and on top of \verb"d", she considers to move \verb"c" away.
Realizing that she cannot put \verb"c" on any mentioned block, the agent attempts to find an extra block and at last, she successfully accomplishes her tasks with two extra blocks \verb"c1" and \verb"c2".

\section{Conclusions}

We now discuss related work other than those we have mentioned in the introduction. Petrick and Bacchus \shortcite{PB02} proposed a planning system with incomplete information and sensing called $\mathbf{PKS}$.
Their system is also based on the domain closure assumption. 
It can only handle a special form of disjunctive knowledge in the form of exclusive disjunctive knowledge. 
Their system is based on approximate progression reasoning procedures without semantic characterizations. 
However, $\mathbf{PKS}$ has support for functions. Classen \etc\ proposed an integration of Golog and planning. However, their implementation of Golog is also based on CWA. Classen and Lakemeyer proposed Golog with disjunctive knowledge bases where their reasoing is also based on SL and they provide a search operator that finds plans within only a fixed belief level $k$. However, their system is also based on regression.

To summarize, in this paper, we have presented a first-order interpreter for knowledge-based Golog with sensing based on exact progression and limited reasoning. We assume infinitely many unique names and handle incomplete information in the form of \properplus\ KBs. Our limited reasoning is based on the subjection logic $\SL$ and so far we only implement reasoning at the $B_0$ level. Our progression is based on the progression algorithm from (LL09). To improve efficiency, we implement these two algorithms by grounding. The interpreter is offline but the programmer can . In the future, we would like to implement reasoning at the $B_1$ level and explore the support of state constraints in our interpreter.

\small
\bibliography{int}
\bibliographystyle{aaai}

\end{document}


\section{Introduction}

When it comes to high-level robotic control, the idea of high-level program execution as embodied by the
Golog language \cite{Golog} provides a useful alternative to planning. Golog is theoretically based on the situation calculus \cite{Rei01}, which is a first-order language. However, current implementations of Golog offer limited first-order capabilities. For example, implementation of classic Golog is based on the closed-world assumption (CWA). Although variants of Golog have been proposed to handle incomplete information and sensing, their implementations resort to dynamic versions of CWA or at least the domain closure assumption (DCA). For example, implementation of IndiGolog \cite{GLS01} is based on a just-in-time assumption, which reduces to a dynamic CWA. The interpreter for knowledge-based Golog as proposed by Reiter \shortcite{Rei01a} is based on DCA and reduces first-order reasoning to propositional one. However, in many real-world applications, it is inappropriate to have CWA, or dynamic CWA, or domain closure axiom.

An essential component of any Golog interpreter is a query evaluation module, which solves the projection problem, that is, decide if a formula holds after a sequence of actions have been performed. Two powerful methods to solve the projection problem are {\em
regression} and {\em progression}. Roughly, regression reduces a
query about the future to a query about the initial knowledge base
(KB). Progression, on the other hand, changes the initial KB
according to the effects of each action and then checks whether the
formula holds in the resulting KB.
One advantage of progression
compared to regression is that after a KB has been progressed, many
queries about the resulting state can be processed without any extra
overhead. Moreover, when the action sequence becomes very long,
regression simply becomes unmanageable. However, current implementations
of Golog are exclusively based on regression. This might be due to the negative result that
in general progression is not first-order definable. However, recently,
Liu and Lakemeyer \shortcite{LL09} showed that for the so-called local-effect actions, progression is always first-order definable and computable.

Golog interpreters can be put into three categories: online, offline, and a combination of the two.
An online interpreter is incomplete because no backtracking is allowed, while an offline interpreter is computationally expensive because of the much larger search space. In the presence of sensing, Reiter's interpreter for knowledge-based Golog is online, while the one for sGolog \cite{Lak99} is offline, outputting a tree of actions. On the other hand, IndiGolog combines online execution with offline execution of parts of programs, specified by the programmer with a search operator. However, unlike sGolog, IndiGolog ignores sensing results during offline execution of programs.
To improve efficiency of Golog interpreters, there has been work on exploiting state-of-the-art planners. For example, Cla{\ss}en and Lakemeyer \shortcite{CL09} proposed to call a planner to achieve a goal during the execution of a Golog program.
Baier \etc\ \shortcite{BFM07} developed an approach for compiling procedural domain control knowledge written in a Golog-like program into a planning instance which can then be solved by a planner.

In this paper, we propose an interpreter for knowledge-based Golog with first-order incomplete information and sensing. We do not assume any of the CWA, dynamic CWA and DCA. The incomplete information is in the form of the so-called \properplus\ KBs \cite{LL02}, which is equivalent to a possibly infinite set of ground clauses. Our solution to the projection problem is based on exact progression and limited reasoning, and we exploit existing results regarding proper$^+$ KBs.
Since the deduction problem for \properplus\ KBs is undecidable, Liu, Lakemeyer and Levesque \shortcite{LLL04} proposed a logic of limited belief called the subjective logic $\SL$, and proved that $\SL$-based reasoning with \properplus\ KBs is decidable. Reasoning based on $\SL$ is logically sound and sometimes complete. Given disjunctive information, it performs unit propagation, but only does case analysis in a limited way.
On the other hand, Liu and Lakemeyer \shortcite{LL09} showed that for a restricted class of local-effect actions and \properplus\ KBs, progression is not only first-order definable but also efficiently computable.
To improve efficiency, we implement the reasoning (right now, we do not do any case analysis) and progression procedures by grounding. The trick here is to use an appropriate number of special constants, which actually carries first-order information.

We provide a search operator, which, unlike in indiGolog, returns a conditional program where branchings are conditioned on the results of sensing actions. We also provide a planning operator, which is used with a program when locally complete information is available, and calls a state-of-the-art planner to generate a sequence of actions constituting a legal execution of the program.

We have experimented our interpreter with Wumpus world, blocks world, Unix domain, and service robot domains; the results showed the feasibility and efficiency of our approach.

%The rest of the paper is organized as follows. In the next section, we introduce the background work of this paper. Then we present the syntax and semantics of LBGolog. Next, we show how to implement progression and query evaluation by grounding. In the following section,
%we describe our implementation of a LBGolog interpreter and prove its correctness. After presenting some experimental results and examples, we discuss related work and conclude.


\subsection{Implementation}
We use the classic data structure of SAT solvers -- counter-based adjacency list to represent a ground clause. In this structure, literals are represented as integers, clauses are represented as lists of literals and have associated indexes. For each clause, there is a counter which keeps track of the number of literals in it. Each atom $p$ is associated with a list of indexes of clauses containing $p$ and a list of indexes of clauses containing $\neg p$. ?? So the main components of a KB are a CNF formula, a bijection between propositional atoms and indexes, and a situation in which the KB holds.

?? When computing resolution between $\rho$ and $C \vee \overline{\rho}$ where $\rho$ is a literal and $C$ is a clause, we simply decrease the counter of $C \vee \overline{\rho}$ and delete $\overline{\rho}$ in it.
When the counter becomes 1, the remaining literal will become a unit clause and trigger unit resolution.
Similarly when a literal $\rho$ is obtained or generated in resolution, we need to delete all the clauses containing it, except $\rho$ itself.
Here the list of indexes of all clauses containing $\rho$ can be obtained in constant time.
For evaluating a clause, we need to search for its subset.
For example, if we need to evaluate a clause, $p \vee \neg q \vee \neg r$, we only need to traverse clauses associated with the propositional atoms, $p$, $q$ and $r$, never considering the others. 